{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791a5744",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "import seaborn as sns # visualization\n",
    "\n",
    "import warnings # Supress warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReadData:\n",
    "    acce: np.ndarray\n",
    "    acce_uncali: np.ndarray\n",
    "    gyro: np.ndarray\n",
    "    gyro_uncali: np.ndarray\n",
    "    magn: np.ndarray\n",
    "    magn_uncali: np.ndarray\n",
    "    ahrs: np.ndarray\n",
    "    wifi: np.ndarray\n",
    "    ibeacon: np.ndarray\n",
    "    waypoint: np.ndarray\n",
    "\n",
    "\n",
    "def read_data_file(data_filename):\n",
    "    acce = []\n",
    "    acce_uncali = []\n",
    "    gyro = []\n",
    "    gyro_uncali = []\n",
    "    magn = []\n",
    "    magn_uncali = []\n",
    "    ahrs = []\n",
    "    wifi = []\n",
    "    ibeacon = []\n",
    "    waypoint = []\n",
    "\n",
    "    with open(data_filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line_data in lines:\n",
    "        line_data = line_data.strip()\n",
    "        if not line_data or line_data[0] == '#':\n",
    "            continue\n",
    "\n",
    "        line_data = line_data.split('\\t')\n",
    "\n",
    "        if line_data[1] == 'TYPE_WAYPOINT':\n",
    "            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER':\n",
    "            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':\n",
    "            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_GYROSCOPE':\n",
    "            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':\n",
    "            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n",
    "            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':\n",
    "            magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n",
    "            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_WIFI':\n",
    "            sys_ts = line_data[0]\n",
    "            ssid = line_data[2]\n",
    "            bssid = line_data[3]\n",
    "            rssi = line_data[4]\n",
    "            lastseen_ts = line_data[6]\n",
    "            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n",
    "            wifi.append(wifi_data)\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_BEACON':\n",
    "            ts = line_data[0]\n",
    "            uuid = line_data[2]\n",
    "            major = line_data[3]\n",
    "            minor = line_data[4]\n",
    "            rssi = line_data[6]\n",
    "            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi]\n",
    "            ibeacon.append(ibeacon_data)\n",
    "            continue\n",
    "\n",
    "\n",
    "    acce = np.array(acce)\n",
    "    acce_uncali = np.array(acce_uncali)\n",
    "    gyro = np.array(gyro)\n",
    "    gyro_uncali = np.array(gyro_uncali)\n",
    "    magn = np.array(magn)\n",
    "    magn_uncali = np.array(magn_uncali)\n",
    "    ahrs = np.array(ahrs)\n",
    "    wifi = np.array(wifi)\n",
    "    ibeacon = np.array(ibeacon)\n",
    "    waypoint = np.array(waypoint)\n",
    "\n",
    "    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint)\n",
    "\n",
    "sample_file = read_data_file(\"../input/indoor-location-navigation/train/5a0546857ecc773753327266/F2/5dccf516c04f060006e6e3c9.txt\")\n",
    "\n",
    "print('acce shape:', sample_file.acce.shape)\n",
    "print('acce_uncali shape:', sample_file.acce_uncali.shape)\n",
    "print('gyro shape:', sample_file.gyro.shape)\n",
    "print('gyro_uncali shape:', sample_file.gyro_uncali.shape)\n",
    "print('magn shape:', sample_file.magn.shape)\n",
    "print('magn_uncali shape:',sample_file.magn_uncali.shape)\n",
    "print('ahrs shape:', sample_file.ahrs.shape)\n",
    "print('wifi shape:', sample_file.wifi.shape)\n",
    "print('ibeacon shape:', sample_file.ibeacon.shape)\n",
    "print('waypoint shape:', sample_file.waypoint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = 1573713056850\n",
    "end_time = 1573713091483\n",
    "\n",
    "print(datetime.fromtimestamp(start_time/1000.0))\n",
    "print(datetime.fromtimestamp(end_time/1000.0))\n",
    "print(datetime.fromtimestamp(end_time/1000.0)-datetime.fromtimestamp(start_time/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887de579",
   "metadata": {},
   "outputs": [],
   "source": [
    "waypoint_df = pd.DataFrame(sample_file.waypoint)\n",
    "waypoint_df.columns = ['timestamp', 'waypoint_x','waypoint_y']\n",
    "display(waypoint_df.style.set_caption('Waypoint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trajectory(trajectory, floor_plan_filename, width_meter, height_meter, title=None, mode='lines + markers + text', show=False):\n",
    "    \"\"\"\n",
    "    Copied from from https://github.com/location-competition/indoor-location-competition-20/blob/master/visualize_f.py\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\t\n",
    "    # add trajectory\n",
    "    size_list = [6] * trajectory.shape[0]\n",
    "    size_list[0] = 10\n",
    "    size_list[-1] = 10\n",
    "\n",
    "    color_list = ['rgba(4, 174, 4, 0.5)'] * trajectory.shape[0]\n",
    "    color_list[0] = 'rgba(12, 5, 235, 1)'\n",
    "    color_list[-1] = 'rgba(235, 5, 5, 1)'\n",
    "\n",
    "    position_count = {}\n",
    "    text_list = []\n",
    "    for i in range(trajectory.shape[0]):\n",
    "        if str(trajectory[i]) in position_count:\n",
    "            position_count[str(trajectory[i])] += 1\n",
    "        else:\n",
    "            position_count[str(trajectory[i])] = 0\n",
    "        text_list.append('        ' * position_count[str(trajectory[i])] + f'{i}')\n",
    "    text_list[0] = 'Start 0'\n",
    "    text_list[-1] = f'End {trajectory.shape[0] - 1}'\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(\n",
    "            x=trajectory[:, 0],\n",
    "            y=trajectory[:, 1],\n",
    "            mode=mode,\n",
    "            marker=dict(size=size_list, color=color_list),\n",
    "            line=dict(shape='linear', color='lightgrey', width=3, dash='dash'),\n",
    "            text=text_list,\n",
    "            textposition=\"top center\",\n",
    "            name='trajectory',\n",
    "    ))\n",
    "\n",
    "    # add floor plan\n",
    "    floor_plan = Image.open(floor_plan_filename)\n",
    "    fig.update_layout(images=[\n",
    "        go.layout.Image(\n",
    "            source=floor_plan,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            x=0,\n",
    "            y=height_meter,\n",
    "            sizex=width_meter,\n",
    "            sizey=height_meter,\n",
    "            sizing=\"contain\",\n",
    "            opacity=1,\n",
    "            layer=\"below\",\n",
    "            )\n",
    "    ])\n",
    "\n",
    "    # configure\n",
    "    fig.update_xaxes(autorange=False, range=[0, width_meter])\n",
    "    fig.update_yaxes(autorange=False, range=[0, height_meter], scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_layout(\n",
    "        title=go.layout.Title(\n",
    "            text=title or \"No title.\",\n",
    "            xref=\"paper\",\n",
    "            x=0,\n",
    "        ),\n",
    "        autosize=True,\n",
    "        width=800,\n",
    "        height=  800 * height_meter / width_meter,\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def visualize_train_trajectory(path):\n",
    "    \"\"\"\n",
    "    Edited from \n",
    "    https://www.kaggle.com/ihelon/indoor-location-exploratory-data-analysis\n",
    "    \"\"\"\n",
    "    _id, floor = path.split(\"/\")[:2]\n",
    "\n",
    "    train_floor_data = read_data_file(f\"../input/indoor-location-navigation/train/{path}\")\n",
    "    with open(f\"../input/indoor-location-navigation/metadata/{_id}/{floor}/floor_info.json\") as f:\n",
    "        train_floor_info = json.load(f)\n",
    "\n",
    "    return visualize_trajectory(\n",
    "        train_floor_data.waypoint[:, 1:3], \n",
    "        f\"../input/indoor-location-navigation/metadata/{_id}/{floor}/floor_image.png\",\n",
    "        train_floor_info[\"map_info\"][\"width\"], \n",
    "        train_floor_info[\"map_info\"][\"height\"],\n",
    "        f\"Visualization of {path}\"\n",
    "    )\n",
    "#visualize_train_trajectory(\"5a0546857ecc773753327266/F2/5d8f094bd5bae80006eb8db0.txt\")\n",
    "#visualize_train_trajectory(\"5a0546857ecc773753327266/F2/5d8f094bb6e29d0006fb8c03.txt\")\n",
    "#visualize_train_trajectory(\"5a0546857ecc773753327266/F2/5dccf511c04f060006e6e3c6.txt\")\n",
    "visualize_train_trajectory(\"5a0546857ecc773753327266/F2/5dccf516c04f060006e6e3c9.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.concatenate([sample_file.acce, \n",
    "sample_file.acce_uncali[:, 1:],\n",
    "sample_file.gyro[:, 1:],\n",
    "sample_file.gyro_uncali[:, 1:],\n",
    "sample_file.magn[:, 1:],\n",
    "sample_file.magn_uncali[:, 1:],\n",
    "sample_file.ahrs[:, 1:],\n",
    "], axis=1)\n",
    "\n",
    "imu_df = pd.DataFrame(temp)\n",
    "\n",
    "imu_df.columns = ['timestamp', 'acce_x','acce_y', 'acce_z','acce_uncali_x','acce_uncali_y', 'acce_uncali_z',\n",
    "'gyro_x','gyro_y', 'gyro_z','gyro_uncali_x','gyro_uncali_y', 'gyro_uncali_z',\n",
    "'magn_x','magn_y', 'magn_z','magn_uncali_x','magn_uncali_y', 'magn_uncali_z',\n",
    "'ahrs_x','ahrs_y', 'ahrs_z']\n",
    "\n",
    "display(imu_df.head(8).style.set_caption('IMU Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d14ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imu_signals(col, uncali = True):\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(14, 9))\n",
    "    ax[0].set_ylabel(f\"{col}_x\")\n",
    "    ax[1].set_ylabel(f\"{col}_y\")\n",
    "    ax[2].set_ylabel(f\"{col}_z\")\n",
    "    if uncali:\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_uncali_x\"], ax=ax[0], label = 'uncali', color='orange')\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_uncali_y\"], ax=ax[1], label = 'uncali', color='orange')\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_uncali_z\"], ax=ax[2], label = 'uncali', color='orange')\n",
    "        ax[0].set_ylabel(f\"{col}_x \\n(calib./uncalib.)\")\n",
    "        ax[1].set_ylabel(f\"{col}_y \\n(calib./uncalib.)\")\n",
    "        ax[2].set_ylabel(f\"{col}_z \\n(calib./uncalib.)\")\n",
    "\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_x\"], ax=ax[0], label='cali', color='cornflowerblue')\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_y\"], ax=ax[1], label='cali', color='cornflowerblue')\n",
    "        sns.lineplot(x=imu_df.timestamp, y=imu_df[f\"{col}_z\"], ax=ax[2], label='cali', color='cornflowerblue')\n",
    "\n",
    "    for i in range(3):\n",
    "        ax[i].set_xlim([start_time, end_time])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_imu_signals('acce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_from_pos(timestamp, pos):\n",
    "    df = pd.DataFrame({'timestamp' : timestamp, 'position' : pos})\n",
    "    df['timestamp_ms'] = df['timestamp'].apply(lambda x: datetime.fromtimestamp(x/1000.0))\n",
    "    df['timedelta_ms'] = df['timestamp_ms'].diff()\n",
    "    df['timedelta_s'] = df['timedelta_ms'].apply(lambda x: x.total_seconds()).fillna(0)\n",
    "    df['velocity'] = (df['position'].diff() / df['timedelta_s']).fillna(0)\n",
    "    df['acceleration'] = (df['velocity'].diff() / df['timedelta_s']).fillna(0)\n",
    "\n",
    "    return df[['timestamp', 'timestamp_ms', 'timedelta_s', 'position', 'velocity', 'acceleration']]\n",
    "\n",
    "def calc_from_acce(timestamp, acce, p_0):\n",
    "    df = pd.DataFrame({'timestamp' : timestamp, 'acceleration' : acce})\n",
    "    df['timestamp_ms'] = df['timestamp'].apply(lambda x: datetime.fromtimestamp(x/1000.0))\n",
    "    df['timedelta_ms'] = df['timestamp_ms'].diff()\n",
    "    df['timedelta_s'] = df['timedelta_ms'].apply(lambda x: x.total_seconds()).fillna(0)\n",
    "    df['velocity'] = (df['acceleration']*df['timedelta_s']).cumsum()\n",
    "    df['position'] = p_0 + (df['velocity']*df['timedelta_s']).cumsum()\n",
    "\n",
    "    return df[['timestamp', 'timestamp_ms', 'timedelta_s', 'position', 'velocity', 'acceleration']]\n",
    "\n",
    "a_df = calc_from_acce(pd.Series([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) * 1000 + start_time, \n",
    "pd.Series([0, 0, 1.2, 1.2, 1.2, 0, 0, 0, -1.2, -1.2, -1.2, 0, 0]), -6)\n",
    "display(a_df.style.set_caption('Calculated Position and Velocity from Acceleration'))\n",
    "\n",
    "b_df = calc_from_pos(a_df.timestamp, a_df.position)\n",
    "display(b_df.style.set_caption('Calculated Acceleration and Velocity from Position'))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(14, 6))\n",
    "sns.lineplot(x=a_df.timestamp, y=a_df.position, ax=ax, color='cornflowerblue', marker='o', label='Position ($m$)')\n",
    "sns.lineplot(x=a_df.timestamp, y=a_df.velocity, ax=ax, color='blue', marker='o', label='Velocity ($m/s$)')\n",
    "sns.lineplot(x=a_df.timestamp, y=a_df.acceleration, ax=ax, color='seagreen', marker='o', label='Acceleration ($m/s^2$)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f360a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_df = pd.DataFrame(sample_file.wifi)\n",
    "wifi_df.columns = ['timestamp', 'ssid', 'bssid', 'rssi', 'last_seen_timestamp']\n",
    "wifi_df = wifi_df.pivot(index='timestamp', columns=['ssid', 'bssid'])['rssi']\n",
    "wifi_df.reset_index(drop=False, inplace=True)\n",
    "wifi_df.style.set_caption('WiFi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n",
    "\n",
    "for i, c in enumerate(wifi_df.columns):\n",
    "    if c != ('timestamp', ''):\n",
    "        sns.lineplot(x=wifi_df.timestamp.astype(int), y=wifi_df[c].replace('NaN', np.nan).astype(float), ax=ax, marker='o', label=c)\n",
    "    if i == 8:\n",
    "        break\n",
    "ax.set_xlim([start_time, end_time])\n",
    "ax.set_ylim([-80, 0])\n",
    "\n",
    "ax.set_ylabel('RSSI')\n",
    "ax.set_title('8 Sample RSSI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import psutil\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from contextlib import contextmanager\n",
    "# -------------------------------------------------\n",
    "# Fixed values\n",
    "# -------------------------------------------------\n",
    "N_SPLITS = 10\n",
    "SEED = 42\n",
    "\n",
    "# -------------------------------------------------\n",
    "# File path definition\n",
    "# -------------------------------------------------\n",
    "LOG_PATH = Path(\"./log/\")\n",
    "LOG_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ba4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Utilities\n",
    "# --------------------------------------------------------\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    t0 = time.time()\n",
    "    p = psutil.Process(os.getpid())\n",
    "    m0 = p.memory_info()[0] / 2. ** 30\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        m1 = p.memory_info()[0] / 2. ** 30\n",
    "        delta = m1 - m0\n",
    "        sign = '+' if delta >= 0 else '-'\n",
    "        delta = math.fabs(delta)\n",
    "        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n",
    "\n",
    "\n",
    "def score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n",
    "    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n",
    "    # noinspection PyTypeChecker\n",
    "    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n",
    "    df.to_csv(LOG_PATH / f\"log_score.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63871412",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = \"../input/indoor-navigation-and-location-wifi-features\"\n",
    "train_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\n",
    "test_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\n",
    "subm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Define parameters for models\n",
    "# --------------------------------------------\n",
    "lgb_params = {'objective': 'root_mean_squared_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 50000,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 90,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.6,\n",
    "    'subsample_freq': 2,\n",
    "    'bagging_seed': SEED,\n",
    "    'reg_alpha': 8,\n",
    "    'reg_lambda': 2,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "lgb_f_params = {'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 50000,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 90,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.6,\n",
    "    'subsample_freq': 2,\n",
    "    'bagging_seed': SEED,\n",
    "    'reg_alpha': 8,\n",
    "    'reg_lambda': 2,\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69492518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Training and inference\n",
    "# ---------------------------------------------\n",
    "score_df = pd.DataFrame()\n",
    "oof = list()\n",
    "predictions = list()\n",
    "for n_files, file in enumerate(train_files):\n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    test_data = pd.read_csv(test_files[n_files], index_col=0)\n",
    "\n",
    "    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n",
    "    preds_x, preds_y = 0, 0\n",
    "    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n",
    "        X_train = data.iloc[trn_idx, :-4]\n",
    "        y_trainx = data.iloc[trn_idx, -4]\n",
    "        y_trainy = data.iloc[trn_idx, -3]\n",
    "        y_trainf = data.iloc[trn_idx, -2]\n",
    "\n",
    "        X_valid = data.iloc[val_idx, :-4]\n",
    "        y_validx = data.iloc[val_idx, -4]\n",
    "        y_validy = data.iloc[val_idx, -3]\n",
    "        y_validf = data.iloc[val_idx, -2]\n",
    "\n",
    "        modelx = lgb.LGBMRegressor(**lgb_params)\n",
    "        with timer(\"fit X\"):\n",
    "            modelx.fit(X_train, y_trainx,\n",
    "                        eval_set=[(X_valid, y_validx)],\n",
    "                        eval_metric='rmse',\n",
    "                        verbose=False,\n",
    "                        early_stopping_rounds=20\n",
    "                        )\n",
    "\n",
    "        modely = lgb.LGBMRegressor(**lgb_params)\n",
    "        with timer(\"fit Y\"):\n",
    "            modely.fit(X_train, y_trainy,\n",
    "                        eval_set=[(X_valid, y_validy)],\n",
    "                        eval_metric='rmse',\n",
    "                        verbose=False,\n",
    "                        early_stopping_rounds=20\n",
    "                        )\n",
    "\n",
    "        modelf = lgb.LGBMClassifier(**lgb_f_params)\n",
    "        with timer(\"fit F\"):\n",
    "            modelf.fit(X_train, y_trainf,\n",
    "                        eval_set=[(X_valid, y_validf)],\n",
    "                        eval_metric='multi_logloss',\n",
    "                        verbose=False,\n",
    "                        early_stopping_rounds=20\n",
    "                        )\n",
    "\n",
    "        oof_x[val_idx] = modelx.predict(X_valid)\n",
    "        oof_y[val_idx] = modely.predict(X_valid)\n",
    "        oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n",
    "\n",
    "        preds_x += modelx.predict(test_data.iloc[:, :-1]) / N_SPLITS\n",
    "        preds_y += modely.predict(test_data.iloc[:, :-1]) / N_SPLITS\n",
    "        preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n",
    "\n",
    "        score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n",
    "        y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n",
    "        print(f\"fold {fold}: mean position error {score}\")\n",
    "        score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n",
    "\n",
    "    print(\"*+\"*40)\n",
    "    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n",
    "    score = comp_metric(oof_x, oof_y, oof_f,\n",
    "    data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n",
    "    oof.append(score)\n",
    "    print(f\"mean position error {score}\")\n",
    "    print(\"*+\"*40)\n",
    "    score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n",
    "\n",
    "    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n",
    "    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n",
    "    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n",
    "    test_preds.columns = subm.columns\n",
    "    test_preds.index = test_data[\"site_path_timestamp\"]\n",
    "    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n",
    "    predictions.append(test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
